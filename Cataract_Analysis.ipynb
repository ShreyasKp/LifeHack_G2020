{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595863337506",
   "display_name": "Python 3.6.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LifeHack 2020- Problem #2**\n",
    "\n",
    "Vision Impairment can be a serious implication on one’s health. According to the key facts stated by the World Health Organization “Globally, at least 2.2 billion people have a vision impairment or blindness, of whom at least 1 billion have a vision impairment that could have been prevented or has yet to be addressed.” Do you have the ability to better detect potential vision issues and help change thousands, if not, millions of lives? \n",
    "\n",
    "For example, the given dataset looks at cataract and normal eye image dataset for cataract detection. Participants are encouraged to use other available datasets to better analyse and share their findings regarding the detection of the potential risk of visual problems detection, preferably relating to the Asia region. Indeed this problem statement covers a wide area of visual impairments and does not need to focus solely on cataract. Participants are free to explore other options of eye disease detection.  \n",
    "\n",
    "* Present Insight into the data by mean of visualization and/or interactive means\n",
    "* Prediction model for eye disease \n",
    "\n",
    "For reference:\n",
    "https://www.kaggle.com/jr2ngb/cataractdataset?Vision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib                  # 2D Plotting Library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns              # Python Data Visualization Library based on matplotlib\n",
    "from sklearn.metrics import classification_report\n",
    "#import geopandas as gpd            # Python Geospatial Data Library\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Dense, Conv2D, GlobalAveragePooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Train / Val / Test folders \n",
    "root_dir = 'cataract_dataset_bundle_archive'\n",
    "normal = '/1_normal'\n",
    "cataract = '/2_cataract'\n",
    "glaucoma = '/2_glaucoma'\n",
    "retina_disease = '/3_retina_disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'cataract_dataset_bundle_archive/train/1_normal'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4bc4df7e0920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/val'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'cataract_dataset_bundle_archive/train/1_normal'"
     ]
    }
   ],
   "source": [
    "#Creating Train / Val / Test folders \n",
    "root_dir = 'cataract_dataset_bundle_archive'\n",
    "classes = ['/1_normal', '/2_cataract', '/2_glaucoma', '/3_retina_disease']\n",
    "\n",
    "for class_type in classes:\n",
    "    os.makedirs(root_dir + '/train' + class_type)\n",
    "    os.makedirs(root_dir + '/val' + class_type)\n",
    "    os.makedirs(root_dir + '/test' + class_type)\n",
    "\n",
    "    src = root_dir + class_type\n",
    "\n",
    "    allFiles = os.listdir(src)\n",
    "    np.random.shuffle(allFiles)\n",
    "    train_Files, val_Files, test_Files = np.split(np.array(allFiles),\n",
    "                                                          [int(len(allFiles)*0.7), int(len(allFiles)*0.85)])\n",
    "                                                          \n",
    "    train_Files = [src+'/'+ name for name in train_Files.tolist()]\n",
    "    val_Files = [src+'/' + name for name in val_Files.tolist()]\n",
    "    test_Files = [src+'/' + name for name in test_Files.tolist()]\n",
    "\n",
    "    print('Class: ', class_type)\n",
    "    print('Total images: ', len(allFiles))\n",
    "    print('Training: ', len(train_Files))\n",
    "    print('Validation: ', len(val_Files))\n",
    "    print('Testing: ', len(test_Files))\n",
    "\n",
    "    for name in train_Files:\n",
    "        shutil.copy(name, root_dir + \"/train\" + class_type)\n",
    "    \n",
    "    for name in val_Files:\n",
    "        shutil.copy(name, root_dir + \"/val\" + class_type)\n",
    "    \n",
    "    for name in test_Files:\n",
    "        shutil.copy(name, root_dir + \"/test\" + class_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processed data is stored in a new directory - \"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Resnet** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'data/train'\n",
    "validation_data_dir = f'data/val'\n",
    "nb_train_samples = 420 \n",
    "nb_validation_samples = 90\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 420 images belonging to 4 classes.\nFound 90 images belonging to 4 classes.\n"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, None, None, 5 0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, None, None, 2 131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, None, None, 2 0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, None, None, 2 0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, None, None, 1 525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, None, None, 1 0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, None, None, 1 0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, None, None, 2 0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, None, None, 2 0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, None, None, 1 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, None, None, 1 0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, None, None, 2 0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, None, None, 2 0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, None, None, 1 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, None, None, 1 0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, None, None, 2 0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, None, None, 2 0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, None, None, 1 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, None, None, 1 0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, None, None, 2 0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, None, None, 2 0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, None, None, 1 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, None, None, 1 0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, None, None, 2 262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, None, None, 2 0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, None, None, 2 590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, None, None, 2 1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, None, None, 2 0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, None, None, 1 263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, None, None, 1 4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, None, None, 1 0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, None, None, 1 0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, None, None, 5 524800      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, None, None, 5 0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, None, None, 5 0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, None, None, 2 2099200     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_add (Add)          (None, None, None, 2 0           conv5_block1_0_bn[0][0]          \n                                                                 conv5_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_out (Activation)   (None, None, None, 2 0           conv5_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, None, None, 5 0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, None, None, 5 0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_add (Add)          (None, None, None, 2 0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_out (Activation)   (None, None, None, 2 0           conv5_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, None, None, 5 1049088     conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, None, None, 5 0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, None, None, 5 2359808     conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, None, None, 5 2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, None, None, 5 0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, None, None, 2 1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_3_bn (BatchNormali (None, None, None, 2 8192        conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_add (Add)          (None, None, None, 2 0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_out (Activation)   (None, None, None, 2 0           conv5_block3_add[0][0]           \n==================================================================================================\nTotal params: 23,587,712\nTrainable params: 23,534,592\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "model.compile(optimizer=SGD(lr=1e-1, momentum=0.9, decay=1e-1 / epochs), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.fit_generator(train_generator, train_generator.n // batch_size, epochs=2, workers=4,\n",
    "#         validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAM seems to give the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 91 images belonging to 4 classes.\n"
    }
   ],
   "source": [
    "test_data_dir = f'data/test'\n",
    "\n",
    "testing_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-------------------------------  TESTING MULTI CLASSIFICATION MODEL  ----------------------------------------\nWARNING:tensorflow:From <ipython-input-21-3f4c1936c18d>:4: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.predict, which supports generators.\n                  precision    recall  f1-score   support\n\n        1_normal       0.52      0.96      0.67        45\n      2_cataract       0.00      0.00      0.00        15\n      2_glaucoma       0.00      0.00      0.00        16\n3_retina_disease       0.12      0.07      0.09        15\n\n        accuracy                           0.48        91\n       macro avg       0.16      0.26      0.19        91\n    weighted avg       0.28      0.48      0.35        91\n\n"
    }
   ],
   "source": [
    "# test model\n",
    "print(\"-------------------------------  TESTING MULTI CLASSIFICATION MODEL  ----------------------------------------\")\n",
    "testing_generator.reset()\n",
    "prediction_index = model.predict_generator(testing_generator, steps=(91 // batch_size) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "prediction_index = np.argmax(prediction_index, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testing_generator.classes, prediction_index, target_names=testing_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 280 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "    train_data_dir = f'data/binary_classifiers/cataract/train'\n",
    "    validation_data_dir = f'data/binary_classifiers/cataract/val'\n",
    "    nb_train_samples = 280\n",
    "    nb_validation_samples = 60\n",
    "    epochs = 10\n",
    "    batch_size = 8\n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "        shuffle=False,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)   \n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers: layer.trainable = False\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n35/35 [==============================] - 54s 2s/step - loss: 0.6909 - accuracy: 0.7143 - val_loss: 0.4986 - val_accuracy: 0.8036\nEpoch 2/5\n35/35 [==============================] - 56s 2s/step - loss: 0.5786 - accuracy: 0.7500 - val_loss: 0.4991 - val_accuracy: 0.8036\nEpoch 3/5\n35/35 [==============================] - 58s 2s/step - loss: 0.5704 - accuracy: 0.7500 - val_loss: 0.4973 - val_accuracy: 0.8036\nEpoch 4/5\n35/35 [==============================] - 57s 2s/step - loss: 0.5886 - accuracy: 0.7500 - val_loss: 0.4985 - val_accuracy: 0.8036\nEpoch 5/5\n35/35 [==============================] - 56s 2s/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 0.4978 - val_accuracy: 0.8036\nCPU times: user 13min 40s, sys: 1min 19s, total: 15min\nWall time: 5min 1s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x184e7a750>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "%%time\n",
    "    model.fit_generator(train_generator, train_generator.n // batch_size, epochs=5, workers=4,\n",
    "        validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 60 images belonging to 2 classes.\n-------------------------------  TESTING BINARY CLASSIFICATION MODEL FOR CATARACT  ----------------------------------------\n              precision    recall  f1-score   support\n\n    1_normal       0.75      1.00      0.86        45\n  2_cataract       0.00      0.00      0.00        15\n\n    accuracy                           0.75        60\n   macro avg       0.38      0.50      0.43        60\nweighted avg       0.56      0.75      0.64        60\n\n"
    }
   ],
   "source": [
    "test_data_dir = f'data/binary_classifiers/cataract/test'\n",
    "\n",
    "testing_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# test model\n",
    "print(\"-------------------------------  TESTING BINARY CLASSIFICATION MODEL FOR CATARACT  ----------------------------------------\")\n",
    "testing_generator.reset()\n",
    "prediction_index = model.predict_generator(testing_generator, steps=(60 // batch_size) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "prediction_index = np.argmax(prediction_index, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testing_generator.classes, prediction_index, target_names=testing_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 280 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_data_dir = f'data/binary_classifiers/glaucoma/train'\n",
    "validation_data_dir = f'data/binary_classifiers/glaucoma/val'\n",
    "nb_train_samples = 280\n",
    "nb_validation_samples = 60\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)   \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n35/35 [==============================] - 67s 2s/step - loss: 0.6128 - accuracy: 0.7143 - val_loss: 0.5058 - val_accuracy: 0.8036\nEpoch 2/5\n35/35 [==============================] - 63s 2s/step - loss: 0.6086 - accuracy: 0.7036 - val_loss: 0.5015 - val_accuracy: 0.8036\nEpoch 3/5\n35/35 [==============================] - 59s 2s/step - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.5591 - val_accuracy: 0.8036\nEpoch 4/5\n35/35 [==============================] - 59s 2s/step - loss: 0.5818 - accuracy: 0.7321 - val_loss: 0.5028 - val_accuracy: 0.8036\nEpoch 5/5\n35/35 [==============================] - 53s 2s/step - loss: 0.5787 - accuracy: 0.7500 - val_loss: 0.5313 - val_accuracy: 0.8036\nCPU times: user 13min 36s, sys: 1min 19s, total: 14min 56s\nWall time: 5min 20s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x15a4d5790>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "%%time\n",
    "    model.fit_generator(train_generator, train_generator.n // batch_size, epochs=5, workers=4,\n",
    "        validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = f'data/binary_classifiers/glaucoma/test'\n",
    "\n",
    "testing_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# test model\n",
    "print(\"-------------------------------  TESTING BINARY CLASSIFICATION MODEL FOR GLAUCOMA  ----------------------------------------\")\n",
    "testing_generator.reset()\n",
    "prediction_index = model.predict_generator(testing_generator, steps=(60 // batch_size) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "prediction_index = np.argmax(prediction_index, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testing_generator.classes, prediction_index, target_names=testing_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 280 images belonging to 2 classes.\nFound 60 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_data_dir = f'data/binary_classifiers/retina_disease/train'\n",
    "validation_data_dir = f'data/binary_classifiers/retina_disease/val'\n",
    "nb_train_samples = 280\n",
    "nb_validation_samples = 60\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)   \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n35/35 [==============================] - 59s 2s/step - loss: 0.6300 - accuracy: 0.7107 - val_loss: 0.5001 - val_accuracy: 0.8036\nEpoch 2/5\n35/35 [==============================] - 59s 2s/step - loss: 0.6045 - accuracy: 0.7143 - val_loss: 0.4999 - val_accuracy: 0.8036\nEpoch 3/5\n35/35 [==============================] - 60s 2s/step - loss: 0.5781 - accuracy: 0.7500 - val_loss: 0.5119 - val_accuracy: 0.8036\nEpoch 4/5\n35/35 [==============================] - 59s 2s/step - loss: 0.6202 - accuracy: 0.7500 - val_loss: 0.5488 - val_accuracy: 0.8036\nEpoch 5/5\n35/35 [==============================] - 56s 2s/step - loss: 0.5831 - accuracy: 0.7500 - val_loss: 0.5059 - val_accuracy: 0.8036\nCPU times: user 13min 45s, sys: 1min 17s, total: 15min 2s\nWall time: 5min 10s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x15a467f90>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "%%time\n",
    "    model.fit_generator(train_generator, train_generator.n // batch_size, epochs=5, workers=4,\n",
    "        validation_data=validation_generator, validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 60 images belonging to 2 classes.\n-------------------------------  TESTING BINARY CLASSIFICATION MODEL FOR RETINA DISEASES  ----------------------------------------\n                  precision    recall  f1-score   support\n\n        1_normal       0.75      1.00      0.86        45\n3_retina_disease       0.00      0.00      0.00        15\n\n        accuracy                           0.75        60\n       macro avg       0.38      0.50      0.43        60\n    weighted avg       0.56      0.75      0.64        60\n\n"
    }
   ],
   "source": [
    "test_data_dir = f'data/binary_classifiers/retina_disease/test'\n",
    "\n",
    "testing_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "    shuffle=False,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size, class_mode='categorical')\n",
    "\n",
    "# test model\n",
    "print(\"-------------------------------  TESTING BINARY CLASSIFICATION MODEL FOR RETINA DISEASES  ----------------------------------------\")\n",
    "testing_generator.reset()\n",
    "prediction_index = model.predict_generator(testing_generator, steps=(60 // batch_size) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "prediction_index = np.argmax(prediction_index, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testing_generator.classes, prediction_index, target_names=testing_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}